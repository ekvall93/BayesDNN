{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekvall/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pencillin(R)</th>\n",
       "      <th>Erythromycin(R)</th>\n",
       "      <th>Multidrug(R)</th>\n",
       "      <th>Amoxicillin(C)</th>\n",
       "      <th>Amoxicillin-Clavunate(C)</th>\n",
       "      <th>Amoxicillin-Total(C)</th>\n",
       "      <th>Cephalosporins(C)</th>\n",
       "      <th>Azithromycin(C)</th>\n",
       "      <th>ConcTotal(C)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999.000000</th>\n",
       "      <td>19.9071</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>222.186</td>\n",
       "      <td>67.4306</td>\n",
       "      <td>289.6166</td>\n",
       "      <td>37.6809</td>\n",
       "      <td>4.12793</td>\n",
       "      <td>358.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999.083333</th>\n",
       "      <td>47.2212</td>\n",
       "      <td>2.51094</td>\n",
       "      <td>9.361640</td>\n",
       "      <td>251.312</td>\n",
       "      <td>71.1567</td>\n",
       "      <td>322.4687</td>\n",
       "      <td>25.5851</td>\n",
       "      <td>2.61499</td>\n",
       "      <td>382.361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pencillin(R)  Erythromycin(R)  Multidrug(R)  Amoxicillin(C)  \\\n",
       "Year                                                                       \n",
       "1999.000000       19.9071          0.00000      0.050406         222.186   \n",
       "1999.083333       47.2212          2.51094      9.361640         251.312   \n",
       "\n",
       "             Amoxicillin-Clavunate(C)  Amoxicillin-Total(C)  \\\n",
       "Year                                                          \n",
       "1999.000000                   67.4306              289.6166   \n",
       "1999.083333                   71.1567              322.4687   \n",
       "\n",
       "             Cephalosporins(C)  Azithromycin(C)  ConcTotal(C)  \n",
       "Year                                                           \n",
       "1999.000000            37.6809          4.12793       358.506  \n",
       "1999.083333            25.5851          2.61499       382.361  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"assets/rspb20170679_si_005.csv\")\n",
    "\n",
    "df.columns = [\"Year\",\"Pencillin(R)\", \"Erythromycin(R)\",\"Multidrug(R)\",\"Amoxicillin(C)\",\n",
    "              \"Amoxicillin-Clavunate(C)\",\"Amoxicillin-Total(C)\",\"Cephalosporins(C)\",\n",
    "              \"Azithromycin(C)\",\"ConcTotal(C)\"]\n",
    "df = df.set_index(\"Year\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multidrug_X = df[[\"Multidrug(R)\",\n",
    "                 \"Azithromycin(C)\",\"Amoxicillin-Total(C)\"]].values\n",
    "Erythromycin_X = df[[\"Erythromycin(R)\",\n",
    "                 \"Azithromycin(C)\",\"Amoxicillin-Total(C)\"]].values\n",
    "Pencillin_x = df[[\"Pencillin(R)\",\"Cephalosporins(C)\",\n",
    "                 \"Azithromycin(C)\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pencillin_x = df[[\"Pencillin(R)\",\"Cephalosporins(C)\",\"Azithromycin(C)\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multidrug_X = df[[\"Multidrug(R)\",\"Cephalosporins(C)\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(data, num_periods=7, f_horizon=1, scale=False):    \n",
    "    n, m = data.shape\n",
    "\n",
    "    x_data = data[:(len(data) - (len(data) % num_periods))]\n",
    "    y_data = data[1:(len(data)-(len(data) % num_periods)) + f_horizon]\n",
    "    \n",
    "    if scale:\n",
    "        std_scale = preprocessing.StandardScaler().fit(x_data, y_data)\n",
    "        x_data = std_scale.transform(x_data)\n",
    "        y_data = std_scale.transform(y_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_batches = x_data.reshape(-1, num_periods, m)\n",
    "    y_batches = y_data.reshape(-1, num_periods, m)\n",
    "    \n",
    "    if scale:\n",
    "        return x_batches, y_batches, std_scale\n",
    "    else:\n",
    "        return x_batches, y_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(data, num_periods, forecast, std_scale=None):\n",
    "    n,m = data.shape\n",
    "    \n",
    "    test_x_setup = data[-(num_periods +  forecast):]\n",
    "    \n",
    "    if std_scale:\n",
    "        test_x_setup = std_scale.transform(test_x_setup)\n",
    "    \n",
    "    testX = test_x_setup[:num_periods].reshape(-1, num_periods, m)\n",
    "    \n",
    "    if std_scale:\n",
    "        testY = std_scale.transform(data[-(num_periods):]).reshape(-1, num_periods, m)\n",
    "    else:\n",
    "        testY = data[-(num_periods):].reshape(-1, num_periods, m)\n",
    "    return testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.distributions import Bernoulli\n",
    "\n",
    "class StochasticRNNLayer:\n",
    "    \"\"\"\n",
    "    StochasticLayer Dense Layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    BN : bool\n",
    "        Batchnormalization\n",
    "    n_in : int\n",
    "        Input nodes\n",
    "    n_out: int\n",
    "        Output nodes\n",
    "    model_prob: float\n",
    "        Dropout probability\n",
    "    model_lam: float\n",
    "        regualarization term\n",
    "    is_training: bool\n",
    "        traing-phase/test-phase        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        Outputlayer\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, n_in, n_out, model_prob, is_training, BN=False, decay=0.99):\n",
    "        \n",
    "        \n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        \n",
    "        self.is_training = is_training    \n",
    "        self.model_prob = model_prob\n",
    "       \n",
    "        self.model_bern = Bernoulli(probs=self.model_prob, dtype=tf.float32)\n",
    "       \n",
    "        #Parameters for BatchNormalization\n",
    "        self.BN = BN\n",
    "        self.scale = tf.Variable(tf.ones([n_out]))\n",
    "        self.beta = tf.Variable(tf.zeros([n_out]))\n",
    "        self.epsilon = 1e-2\n",
    "        self.mean = tf.Variable(tf.zeros([n_out]), trainable=False)\n",
    "        self.var = tf.Variable(tf.ones([n_out]), trainable=False)\n",
    "        self.decay = decay\n",
    "\n",
    "    def __call__(self, X, activation=tf.identity):\n",
    "        \n",
    "        basic_cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "            tf.contrib.rnn.BasicRNNCell(num_units=self.n_in, activation=tf.nn.relu),\n",
    "            output_size=self.n_in\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "        basic_cell = tf.contrib.rnn.DropoutWrapper(basic_cell, input_keep_prob=self.model_prob[0], output_keep_prob=self.model_prob[1], state_keep_prob=self.model_prob[2])\n",
    "        \n",
    "            \n",
    "        rnn_output, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #rnn_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(self.n_in), tf.contrib.rnn.BasicLSTMCell(self.n_in)])\n",
    "        #outputs, states = tf.contrib.rnn.static_rnn(rnn_cell, X, dtype=tf.float32)\n",
    "            \n",
    "        #print(\"rnn_output\",rnn_output.shape)\n",
    "        output = tf.reshape(rnn_output, [-1, self.n_in])\n",
    "        \n",
    "        #output = outputs[-1]\n",
    "        \n",
    "        \n",
    "        #output = rnn_output\n",
    "        #print(\"data\",X.shape)\n",
    "        #print(\"output\",output.shape)\n",
    "        #print(\"mask\",self.model_W.shape)\n",
    "        #output = activation(tf.matmul(output, self.model_W) + self.model_m)\n",
    "        \n",
    "        if self.BN:\n",
    "            output = self.batch_norm_wrapper(output)\n",
    "                \n",
    "        #if self.model_M.shape[1] == m:\n",
    "        #    output = tf.squeeze(output)\n",
    "        return output\n",
    "\n",
    "   \n",
    "    \n",
    "    def batch_norm_wrapper(self, inputs):\n",
    "        \"\"\"\n",
    "        Batchnormalization\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : array\n",
    "            Batch input\n",
    "        is_training : bool\n",
    "            training phase/test phase\n",
    "        decay: float\n",
    "            Decrease training of popoulation mean and variance.    \n",
    "        Returns\n",
    "        -------\n",
    "        array\n",
    "            Normalized batched\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        def BN_train():\n",
    "            \"\"\"\n",
    "            Batchnormalization training\n",
    " \n",
    "            Returns\n",
    "            -------\n",
    "            array\n",
    "                Normalized train batch\n",
    "            \"\"\"\n",
    "            batch_mean, batch_var = tf.nn.moments(inputs,[0])\n",
    "            train_mean = tf.assign(self.mean, self.mean * self.decay + batch_mean * (1 - self.decay))\n",
    "            train_var = tf.assign(self.var, self.var * self.decay + batch_var * (1 - self.decay))\n",
    "            #train_mean = tf.assign(self.mean, self.mean + batch_mean)\n",
    "            #train_var = tf.assign(self.var, self.var + batch_var)\n",
    "            \n",
    "            with tf.control_dependencies([train_mean, train_var]):\n",
    "                return tf.nn.batch_normalization(inputs,\n",
    "                    batch_mean, batch_var, self.beta, self.scale, self.epsilon)\n",
    "            \n",
    "        def BN_test():\n",
    "            \"\"\"\n",
    "            Batchnormalization test\n",
    " \n",
    "            Returns\n",
    "            -------\n",
    "            array\n",
    "                Normalized test batched\n",
    "            \"\"\"\n",
    "            return tf.nn.batch_normalization(inputs,\n",
    "                self.mean, self.var, self.beta, self.scale, self.epsilon)\n",
    "        \n",
    "        \n",
    "        return tf.cond(self.is_training, BN_train, BN_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(num_periods, features, learning_rate=0.01, dp_prob=np.array([1.0,1.0,1.0]), BN=False, decay=0.99,hidden=100,bs=10):\n",
    "    #num_periods = x_batches.shape[1]\n",
    "    inputs = features\n",
    "    hidden = hidden\n",
    "    #output = features\n",
    "    output = 1\n",
    "    model_prob = dp_prob\n",
    "    learning_rate = learning_rate\n",
    "\n",
    "\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, num_periods, inputs])\n",
    "    \n",
    "    #X = tf.reshape(z, [-1, num_periods*inputs])\n",
    "    #X = tf.split(X, num_periods, 1)\n",
    "    \n",
    "    \n",
    "    y = tf.placeholder(tf.float32, [None, num_periods, output])\n",
    "\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    Layer_1 = StochasticRNNLayer(hidden, hidden, model_prob, is_training ,BN=BN, decay=decay)\n",
    "\n",
    "    z_1 = Layer_1(X, tf.nn.relu)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    stacked_outputs = tf.layers.dense(z_1, output)\n",
    "    y_pred = tf.reshape(stacked_outputs, [-1, num_periods, output])\n",
    "    \n",
    "    sse = tf.reduce_sum(tf.square(y_pred - y)) \n",
    "\n",
    "    mse = sse / bs\n",
    "    \n",
    "    model_loss = (\n",
    "        # Negative log-likelihood.\n",
    "        sse \n",
    "                ) / bs\n",
    "    \n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(model_loss)\n",
    "\n",
    "    return (X, y), train_step, mse, y_pred, tf.train.Saver(), is_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_batches,y_batch,iterations=2000, verbose =True, bs=10):\n",
    "    \"\"\"\n",
    "    Train model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    iterations : int\n",
    "        Number of iterations\n",
    "    verbose : bool\n",
    "        Verbose\n",
    "    bs: int\n",
    "        batch-size\n",
    "    \"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(iterations):\n",
    "            #Run it in batches.\n",
    "            test_idx = np.arange(0 , len(x_batches[1]))\n",
    "            #np.random.shuffle(test_idx)\n",
    "            X_batch = x_batches[test_idx[:bs]]\n",
    "            y_batch = y_batches[test_idx[:bs]]\n",
    "        \n",
    "        \n",
    "            train_step.run(feed_dict={X_input: X_batch, y_input: y_batch, is_training:True})\n",
    "            if verbose:\n",
    "                if i % 100 == 0:\n",
    "                    print(i)\n",
    "                    mse = sess.run(model_mse, {X_input: X_batch, y_input: y_batch, is_training:True})\n",
    "                    print(\"Iteration {}, Mean squared errror: {:.7f}\".format(i, mse))\n",
    "        saved_model = saver.save(sess, 'temp/temp-bn-save')\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_batches,X_test,features,samples=1000, bs=10,BN=False):\n",
    "    \"\"\"\n",
    "    Test model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : int\n",
    "        Monte Carlo Samples\n",
    "    bs : int\n",
    "        Batchnorm samples\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, 'temp/temp-bn-save')\n",
    "    \n",
    "\n",
    "        Y_sample = np.zeros((samples, x_batches.shape[1], features))\n",
    "        for i in range(samples):       \n",
    "            if BN:\n",
    "                test_idx = np.arange(0 , x_batches.shape[0])\n",
    "                np.random.shuffle(test_idx)\n",
    "                model_pred.eval({X_input: x_batches[test_idx[:bs]],  is_training: True})\n",
    "            Y_sample[i] = sess.run(model_pred, {X_input: X_test, is_training: False})\n",
    "        return Y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(y_samples, y_test):\n",
    "    if True:\n",
    "        plt.figure(figsize=(8,6))\n",
    "    for i in range(samples):\n",
    "        plt.plot(pd.Series(np.ravel(y_samples[i])), \"b-\", alpha=1. / 200)\n",
    "    plt.plot(pd.Series(np.ravel(y_test)), \"ro\", markersize=10, label=\"Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDNN Multidrug rescistance Forecasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [8.11111111e-01, 9.35555556e-01, 5.54444444e-01, 7.72222222e-01,\n",
    "        7.20000000e+01, 6.00000000e+00, 7.74263683e-04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_periods, f_horizon = 7, 1\n",
    "decay=param[0]\n",
    "bs = int(param[5])\n",
    "dp_prob = np.array([param[1],param[2],param[3]])\n",
    "BN=True\n",
    "hidden= int(param[4])\n",
    "samples = 3000\n",
    "iterations=  3 * 1000\n",
    "lr = param[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Multidrug_X.shape[1]\n",
    "x_batches, y_batches = train_data(Multidrug_X, num_periods=num_periods, f_horizon=f_horizon)\n",
    "X_test, Y_test = test_data(Multidrug_X, num_periods,f_horizon)\n",
    "X_test, Y_test = np.expand_dims(x_batches[-1,:,:],0), np.expand_dims(y_batches[-1,:,:],0)\n",
    "x_batches, y_batches = x_batches[:-1,:,:], y_batches[:-1,:,:]\n",
    "y_batches = np.expand_dims(y_batches[:,:,0],2)\n",
    "Y_test = np.expand_dims(Y_test[:,:,0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_lam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8e38ae0d4af4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m (X_input, y_input), train_step, model_mse, _, saver, is_training = build_graph(num_periods,features,\n\u001b[1;32m      3\u001b[0m                                                                 \u001b[0mBN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdp_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                                                 \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                                               )\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-520aec98082d>\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(num_periods, features, learning_rate, dp_prob, BN, decay, hidden, bs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mLayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStochasticRNNLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_lam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mBN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mz_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayer_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_lam' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "(X_input, y_input), train_step, model_mse, _, saver, is_training = build_graph(num_periods,features,\n",
    "                                                                BN=BN,decay=decay,dp_prob=dp_prob,hidden=hidden,\n",
    "                                                                bs=bs,learning_rate=lr\n",
    "                                                                              )\n",
    "train(x_batches, y_batches, iterations=iterations,verbose = True, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_lam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5e5ed2fb7f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m (X_input, y_input), train_step, model_mse, model_pred, saver, is_training = build_graph(num_periods,features,\n\u001b[1;32m      3\u001b[0m                                                                 \u001b[0mBN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdp_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdp_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                                                 \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                                        )\n",
      "\u001b[0;32m<ipython-input-10-520aec98082d>\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(num_periods, features, learning_rate, dp_prob, BN, decay, hidden, bs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mLayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStochasticRNNLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_lam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mBN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mz_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayer_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_lam' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "(X_input, y_input), train_step, model_mse, model_pred, saver, is_training = build_graph(num_periods,features,\n",
    "                                                                BN=BN,decay=decay,dp_prob=dp_prob,hidden=hidden,\n",
    "                                                                bs=bs,learning_rate=lr\n",
    "                                                                                       \n",
    "                                                                                       )\n",
    "Y_sample_DP = test(x_batches,X_test,features,samples, bs=bs,BN=BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_sample_DP = np.expand_dims(Y_sample_DP[:,:,0],-1)\n",
    "Y_test = np.expand_dims(Y_test[:,:,0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Y_sample_DP, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations=  7 ** 1000\n",
    "param = dict()\n",
    "param[\"decay\"] = np.linspace(0.7,0.95,10)\n",
    "\n",
    "param[\"dp1\"] = np.linspace(0.5,0.99,10)\n",
    "param[\"dp2\"] = np.linspace(0.5,0.99,10)\n",
    "param[\"dp3\"] = np.linspace(0.5,0.99,10)\n",
    "\n",
    "param[\"hidden\"] = np.linspace(10,150,10)\n",
    "param[\"bs\"] = np.linspace(3,7,5)\n",
    "param[\"lr\"] = np.geomspace(0.0001,0.01,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param[\"bs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_param = list()\n",
    "save_predictions = list()\n",
    "save_loss = list()\n",
    "for i in range(100):\n",
    "    decay = param[\"decay\"][np.random.choice(len(param[\"decay\"]),1)][0]\n",
    "    \n",
    "    dp1 = param[\"dp1\"][np.random.choice(len(param[\"dp1\"]),1)][0]\n",
    "    dp2 = param[\"dp2\"][np.random.choice(len(param[\"dp2\"]),1)][0]\n",
    "    dp3 = param[\"dp3\"][np.random.choice(len(param[\"dp3\"]),1)][0]\n",
    "    dp_prob = np.array([dp1,dp2,dp3])\n",
    "    \n",
    "    \n",
    "    hidden = int(param[\"hidden\"][np.random.choice(len(param[\"hidden\"]),1)][0])\n",
    "    bs = int(param[\"bs\"][np.random.choice(len(param[\"bs\"]),1)][0])\n",
    "\n",
    "    lr = param[\"lr\"][np.random.choice(len(param[\"lr\"]),1)][0]\n",
    "    \n",
    "    save_param.append([decay,dp1,dp2,dp3,hidden,bs,lr])\n",
    "    \n",
    "    \n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    (X_input, y_input), train_step, model_mse, _, saver, is_training = build_graph(num_periods,features,\n",
    "                                                                BN=BN,decay=decay,dp_prob=dp_prob,hidden=hidden,\n",
    "                                                                bs=bs,learning_rate=lr\n",
    "                                                                              )\n",
    "    train(x_batches, y_batches, iterations=iterations,verbose = False, bs=bs)\n",
    "    tf.reset_default_graph()\n",
    "    (X_input, y_input), train_step, model_mse, model_pred, saver, is_training = build_graph(num_periods,features,\n",
    "                                                                                        BN=BN,decay=decay,\n",
    "                                                                                        dp_prob=dp_prob,hidden=hidden,\n",
    "                                                                                       \n",
    "                                                                                            learning_rate=lr\n",
    "                                                                                       )\n",
    "    Y_sample_DP = test(x_batches,X_test,features,samples, bs=bs,BN=BN)\n",
    "    Y_sample_DP = np.expand_dims(Y_sample_DP[:,:,0],-1)\n",
    "    \n",
    "    save_predictions.append(Y_sample_DP)\n",
    "    Y_test = np.expand_dims(Y_test[:,:,0],-1)\n",
    "    y_ = Y_sample_DP.mean(axis=0).flatten()\n",
    "    Y_test_ = Y_test.flatten()\n",
    "    loss = np.mean(Y_test_ - y_)**2\n",
    "    print(\"#####\",i, loss,\"####\")\n",
    "    save_loss.append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.array(save_loss) > 10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.array(save_loss) < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(save_param)[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(save_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#f = np.array(save_predictions)[ix]\n",
    "f = np.array(save_predictions)\n",
    "for i, y_pred in enumerate(f):\n",
    "    #print(np.std(y_pred,axis=0))\n",
    "    plot(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDNN Erythromycin rescistance Forecasting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay=0.9\n",
    "bs = 5\n",
    "dp_prob = 0.15\n",
    "BN=True\n",
    "hidden= 500\n",
    "samples = 3000\n",
    "iterations=  5 * 1000\n",
    "model_lam = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_periods, f_horizon = 7, 1\n",
    "features = Erythromycin_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batches, y_batches = train_data(Erythromycin_X, num_periods=num_periods, f_horizon=f_horizon)\n",
    "X_test, Y_test = test_data(Erythromycin_X, num_periods,f_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batches = np.expand_dims(y_batches[:,:,0],2)\n",
    "Y_test = np.expand_dims(Y_test[:,:,0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "(X_input, y_input), train_step, model_mse, _, saver, is_training = build_graph(num_periods,features,\n",
    "                                                                BN=BN,decay=decay,dp_prob=dp_prob,hidden=hidden,\n",
    "                                                                bs=bs,model_lam=model_lam\n",
    "                                                                              )\n",
    "train(x_batches, y_batches, iterations=iterations,verbose = True, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "(X_input, y_input), train_step, model_mse, model_pred, saver, is_training = build_graph(num_periods,features,\n",
    "                                                                                        BN=BN,decay=decay,\n",
    "                                                                                        dp_prob=dp_prob,hidden=hidden,\n",
    "                                                                                       model_lam=model_lam\n",
    "                                                                                       )\n",
    "Y_sample_DP = test(x_batches,X_test,features,samples, bs=bs,BN=BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_sample_DP = np.expand_dims(Y_sample_DP[:,:,0],-1)\n",
    "Y_test = np.expand_dims(Y_test[:,:,0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Y_sample_DP, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDNN Pencillin rescistance Forecasting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay=0.9\n",
    "bs = 5\n",
    "dp_prob = 0.95\n",
    "BN=True\n",
    "hidden= 500\n",
    "samples = 3000\n",
    "iterations=  5 * 1000\n",
    "model_lam = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_periods, f_horizon = 7, 1\n",
    "features = Pencillin_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batches, y_batches = train_data(Pencillin_x, num_periods=num_periods, f_horizon=f_horizon)\n",
    "X_test, Y_test = test_data(Pencillin_x, num_periods,f_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batches = np.expand_dims(y_batches[:,:,0],2)\n",
    "Y_test = np.expand_dims(Y_test[:,:,0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "(X_input, y_input), train_step, model_mse, _, saver, is_training = build_graph(num_periods,features,\n",
    "                                                                BN=BN,decay=decay,dp_prob=dp_prob,hidden=hidden,\n",
    "                                                                bs=bs,model_lam=model_lam\n",
    "                                                                              )\n",
    "train(x_batches, y_batches, iterations=iterations,verbose = True, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "(X_input, y_input), train_step, model_mse, model_pred, saver, is_training = build_graph(num_periods,features,\n",
    "                                                                                        BN=BN,decay=decay,\n",
    "                                                                                        dp_prob=dp_prob,hidden=hidden,\n",
    "                                                                                       model_lam=model_lam\n",
    "                                                                                       )\n",
    "Y_sample_DP = test(x_batches,X_test,features,samples, bs=bs,BN=BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_sample_DP = np.expand_dims(Y_sample_DP[:,:,0],-1)\n",
    "Y_test = np.expand_dims(Y_test[:,:,0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Y_sample_DP, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
